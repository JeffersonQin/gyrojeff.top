---
allowComment: true
allowFeed: true
allowPing: true
authorId: 1
categories: [知识]
created: '2021-10-27 10:38:00'
fields: {customSummary: '', mathjax: 'true', noThumbInfoStyle: default, outdatedNotice: 'no',
  reprint: standard, thumb: 'https://cdn.jsdelivr.net/gh/JeffersonQin/blog-asset@latest/usr/picgo/20211027103600.png',
  thumbChoice: default, thumbDesc: '', thumbSmall: '', thumbStyle: default}
modified: '2021-10-27 10:39:01'
parent: 0
password: ''
slug: expectation-of-product
status: publish
tags: [Math, 概率论]
template: ''
title: 理解随机变量平方的期望
type: post
---
# 理解随机变量平方的期望

今天朋友问我了个问题，讨论如何理解 $E[X^2]$。

## 问题引入

我们从下面这个著名的式子出发：

$$
\begin{aligned}
    \operatorname{Var}[X]
    =&\sum_i(E[X] - x_i) ^ 2 p_i \\ 
    =&E[(E[X] - X)^2] \\ 
    =&E[E^2[X] - 2XE[X] + X^2] \\
    =&E^2[X] - 2E^2[X] + E[X^2] \\ 
    =& E[X^2] - E^2[X]
\end{aligned}
$$

其中，

$$
    E[X^2] = \sum_i x_i^2p_i
$$

这里产生了 $E[X^2]$，我们想要理解为何这么定义。

## 随机变量相乘的期望

现在有随机变量 $X, Y$，下面是期望 $E[XY]$ 的定义：考虑随机变量 $X$, $Y$ 的乘积为一个新的随机变量 $Z$，考虑这个随机变量的分布，所以可以表达为：

$$
    E[XY] = E[Z] = \sum_i Z_i p_{zi}
$$

## 定理：两个相互独立的随机变量乘积的期望是这两个随机变量期望的乘积

定理：若随机变量 $X$, $Y$ 相互独立，则

$$
    E[XY] = E[X]E[Y]
$$

证明：

对于离散随机变量 $X$, $Y$

$$
\begin{aligned}
    E[XY] &= \sum_i \sum_j x_i y_j f_{xy} (x_i, y_j) \\
    &= \sum_i \sum_j x_i y_i f_x (x_i) f_y (y_j) \\ 
    &= \Big ( \sum_i x_i f_x (x_i) \Big) \Big ( \sum_j y_j f_y (y_j) \Big ) \\ 
    &= E[X] E[Y]
\end{aligned}
$$

对于连续随机变量 $X$, $Y$:

$$
\begin{aligned}
    E[XY] &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y f_{xy} (x, y) \mathrm dx \mathrm dy \\ 
    &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y f_x (x) f_y (y) \mathrm dx \mathrm dy \\ 
    &= \Big ( \int_{-\infty}^{\infty} x f_x (x) \mathrm dx \Big ) \Big ( \int_{-\infty}^{\infty} y f_y (y) \mathrm dy \Big ) \\ 
    &= E[X] E[Y]
\end{aligned}
$$

注意：上述式子成立的条件是 $X$, $Y$ 相互独立，即

$$
    f_{xy} (x_i, y_j) = f_x (x_i) f_y (y_j)
$$

$$
    f_{xy} (x, y) = f_x (x) f_y (y)
$$

## 随机变量平方的期望与上述结论不相违背

朋友说上述的结论与随机变量平方的期望的定义相违背，但实则不然。下面是他认为的式子：

$$
    E[X^2] = \Big( \sum _ i x_i p_i \Big ) \Big( \sum _ i x_i p_i \Big ) = E^2[X]
$$

然而他忽略了一个重要的事实，$X$ 与 $X$ 不独立，即 $X^2$ 的分布情况和 $X$ 一样（除了数值都平方了），所以

$$
    E[X^2] = \sum _ i x_i^2 p_i
$$

QED.
