---
allowComment: true
allowFeed: true
allowPing: true
authorId: 1
categories: [技术]
created: '2022-04-02 20:37:23'
fields: {customSummary: '', mathjax: auto, noThumbInfoStyle: default, outdatedNotice: 'no',
  reprint: standard, thumb: '', thumbDesc: '', thumbSmall: '', thumbStyle: default}
modified: '2022-04-02 20:37:23'
parent: 0
password: ''
slug: 深度学习分布偏移理论
status: publish
tags: [DL, ML, Math, 机器学习, 深度学习]
template: ''
title: 深度学习分布偏移理论
type: post
---
本节主要为以下内容的笔记：https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/environment.html

## 训练到底在做什么？

训练其实是在最小化通过数据集得到的经验风险：

$$
	\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),
$$

其中 $l$ 是损失函数，用来度量对于给定的标签 $y_i$，预测值 $f(\mathbf {x}_i)$ 的糟糕程度。

但是我们想要得到的又是什么呢？我们想要的是最小化实际风险，也就是最小化下面这个期望：

$$
	E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy
$$

然而在实践中，我们通常无法获得总体数据。 因此，经验风险最小化， 是一种实用的机器学习策略，希望能近似最小化真实风险。

## 协变量偏移

在不同分布偏移中，协变量偏移可能是最为广泛研究的。这里我们假设：虽然输入的分布可能随时间而改变，但标签函数（即条件分布 $P(y \mid \mathbf{x})$ ）没有改变。统计学家称之为**协变量偏移** （covariate shift），因为这个问题是由于协变量（特征）分布的变化而产生的。虽然有时我们可以在不引用因果关系的情况下对分布偏移进行推断，但在我们认为 $\mathbf{x}$ 导致 $y$ 的情况下，协变量偏移是一种自然假设。

## 协变量偏移的例子

* 现在我们使用猫狗照片 $\mathbf x$ 来训练一个猫狗分类器来给出猫狗标签 $y$
* 训练数据集是真实的猫狗图片
* 测试数据集是卡通形象的猫狗图片
* 虽然猫狗图片的分布 $P(\mathbf{x})$ 被改变了（测试集上图片的分布改变了），但是猫狗图片对于猫狗分类的条件分布 $P(y \mid \mathbf{x})$ 并未改变（确定了照片，分类也就确定了）
* 这是由于特征分布的变化导致的（协变量的变化，这里的协变量就是图片风格）
* 在这种情况下，是猫狗图片 $\mathbf x$ 导致猫狗分类 $y$ 的，所以我们一般可以使用协变量偏移假设

## 协变量偏移的纠正

见：https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/environment.html#subsec-covariate-shift-correction

总结一下：

设目标分布为 $p(x)$，源分布为 $q(x)$，则根据协变量偏移假设

$$
	p(y \mid \mathbf x) = q(y \mid \mathbf x)
$$

则

$$
	\begin{aligned}
		&\int\int l(f(\mathbf{x}), y) p(\mathbf{x},y) \;d\mathbf{x}dy \\
		=&\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy \\
		=&\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
$$

所以现在我们需要一个额外的权重

$$
	\beta_i \stackrel{\mathrm{def}}{=} \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}
$$

来调整训练方式：

$$
	\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i)
$$

为了得到这个权重，我们可以通过训练一个二元分类器，来学习数据到底是来自于训练集还是来自于测试集。如果无法区分这两个分布，则意味着想相关的样本可能来自这两个分布中的任何一个。 另一方面，任何可以很好区分的样本都应该相应地显著增加或减少权重。

接下来是训练的方法：为了简单起见，假设我们分别从 $p(x)$ 和 $q(x)$ 两个分布中抽取相同数量的样本。 现在用标签 $z$ 表示：从 $p$ 抽取的数据为 $1$，从 $q$ 抽取的数据为 $-1$。 

根据上面的假设，我们有：

$$
	P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})}
$$

$$
	P(z=-1 \mid \mathbf{x}) = \frac{q(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})}
$$

所以混合分布，也就是权重 $\beta$ 的分布可以由下式给出：

$$
	\frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})} = \beta (\mathbf x)
$$

下一个问题就是如何训练得到 $P(z=1 \mid \mathbf{x})$ 了。我们可以使用对数回归：

$$
	P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))} = \sigma(h(\mathbf x))
$$

这样的话：

$$
	\beta_i = \frac{1/(1 + \exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1 + \exp(-h(\mathbf{x}_i)))} = \exp(h(\mathbf{x}_i))
$$

## 标签偏移

**标签偏移**（label shift）描述了与协变量偏移相反的问题。这里我们假设标签边缘概率 $P(y)$ 可以改变，但是类别条件分布 $P(\mathbf{x} \mid y)$ 在不同的领域之间保持不变。当我们认为 $y$ 导致 $\mathbf{x}$ 时，标签偏移是一个合理的假设。例如，预测患者的疾病，我们可能根据症状来判断，即使疾病的相对流行率随着时间的推移而变化。标签偏移在这里是恰当的假设，因为疾病会引起症状。在另一些情况下，标签偏移和协变量偏移假设可以同时成立。例如，当标签是确定的，即使 $y$ 导致 $\mathbf{x}$ ，协变量偏移假设也会得到满足。有趣的是，在这些情况下，使用基于标签偏移假设的方法通常是有利的。这是因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维的）对象。

## 标签偏移的例子

* 现在我们通过症状 $\mathbf x$ 来预测疾病 $y$
* 然而，疾病随着时间的推移，疾病的流行程度发生了变化，也就是 $P(y)$ 发生了变化
* 但是尽管如此，一种确定的疾病导致的症状是不怎么会发生改变的，也就是 $P(\mathbf x \mid y)$ 基本保持不变
* 注意：这个情况下是 $y$ 决定 $\mathbf x$，所以我们就可以使用标签偏移假设

## 标签偏移的纠正

见：https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/environment.html#id14

总结一下：

设目标分布为 $p(x)$，源分布为 $q(x)$，则标签偏移假设

$$
	p(\mathbf x \mid y) = q(\mathbf x \mid y)
$$

则

$$
	\begin{aligned}
    	&\int\int l(f(\mathbf{x}), y) p(\mathbf{x},y) \;d\mathbf{x}dy \\
		=&\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy \\
		=&\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy
	\end{aligned}
$$

我们同样需要一个额外的权重：

$$
	\beta_i \stackrel{\mathrm{def}}{=} \frac{p(y_i)}{q(y_i)}
$$

其中，$q(y)$ 很容易估计，只需要使用训练数据集进行计算即可：

$$
	q(y_i) = \frac {\sum_{j=1}^n 1 \{y_i = y_j\}} {n}
$$

但是 $p(y)$ 就没有这么容易了。我们需要另辟蹊径。

虽然我们不能获得真实数据，但是我们有测试数据，我们可以用测试数据来估计真实数据。令 $\mu(\hat \mathbf y) \in \mathbb R^k$ 为模型测试时各个标签的预测均值，即 $\mu(\hat y_i)$ 为预测标签为 $i$ 时的预测均值。那么，我们可以有：

$$
	\mathbf Cp(\mathbf y) = \mu (\mathbf y)
$$

其中，$\mathbf C$ 是一个 $k \times k$ 的混淆矩阵，其中 $c_{ij}$ 代表验证集中真实标签为 $j$ 但是模型预测为 $i$ 的占比。因为作为一个估计，我们将矩阵乘法按照行向量拆解来看 $\sum_{j = 1}^k c_{ij} p(y_j) = \mu (\hat y_i)$。

对于 $\mathbf C$，应该存在 $\mathbf C^{-1}$，这样我们就能得到 $p(\mathbf y)$

$$
	p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})
$$

也就能得到权重 $\beta$.
